{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "- Video 01 = https://www.youtube.com/watch?v=dIUTsFT2MeQ&list=WL&index=28\n",
    "- Main Textbook = http://spacy.pythonhumanities.com/\n",
    "- Text Files Website = http://www.textfiles.com/news/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers = Spact objects that contains a large quantityt of data about a text. When analyzing texts with spaCy framework, we create different container objects to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20784 4676\n"
     ]
    }
   ],
   "source": [
    "with open(\"attachments/text/A01.txt\", \"r\") as f:\n",
    "    text = f.read() # text object (read from file)\n",
    "\n",
    "doc = nlp(text) #create a doc object (object of spacy library)by calling the nlp obkect we created before and passing th text as a parameter\n",
    "\n",
    "print(len(text), len(doc)) # the length of the DOC object would be much shorter than the plainfully read text. Lets eamine it further:\n",
    "#this is because each item in the text object is a single character while each item in the doc object is a token (word, punctuation, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Voundary detection:\n",
    "Splitting text to sentences by period - doesn't always wor, because of occasional other uses of a period \".\". \n",
    "Luckily Spacy allows us to seperate the document to sentence easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapping\n"
     ]
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "token_17_3 = sentences[17][3]\n",
    "print(token_17_3.text) #3rd word of the 17th sentence is \"snapping\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Ruler\n",
    "- token.left_edge\n",
    "- token.right_edge\n",
    "- token.ent_type\n",
    "- token.ent_type_\n",
    "- token.ent_iob_\n",
    "- token.lemma_    -   get the original verb of the word (the lemma - TO DEFINE - of it)\n",
    "- token.morph\n",
    "- token.pos_  -   Part Of Speech\n",
    "- token.dep_\n",
    "- token.lang_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike PROPN nsubj\n",
      "enjoys VERB ROOT\n",
      "playing VERB xcomp\n",
      "football NOUN dobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text = \"Mike enjoys playing football.\"\n",
    "doc_02 = nlp(text)\n",
    "for token in doc_02:\n",
    "    print(token.text, token.pos_, token.dep_) #gives us a perfect breakdown of all parts of the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cb2c9b4f5ece4231b338883b87fc3780-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mike</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enjoys</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">playing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">football.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cb2c9b4f5ece4231b338883b87fc3780-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cb2c9b4f5ece4231b338883b87fc3780-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cb2c9b4f5ece4231b338883b87fc3780-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cb2c9b4f5ece4231b338883b87fc3780-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cb2c9b4f5ece4231b338883b87fc3780-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cb2c9b4f5ece4231b338883b87fc3780-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc_02, style = \"dep\") #shows us how the sentence (doc_02) is structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    entity = ent.text, ent.label_ # will print each entity from te document (text, label) (currently defined as varieble entity because of large output)\n",
    "    \n",
    "#it can also be visualized really nicely using:\n",
    "displacy.render(doc, style = \"ent\") #which will color code the entitites within the document for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LESSON 3\n",
    "\n",
    "word vectors = numerical representations of words in multidimesional spae through matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\") # larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knight Lightning\n",
      "arrived a little before 6:00 and handed out some literature, along with a\n",
      "kooky little button.\n"
     ]
    }
   ],
   "source": [
    "with open (\"attachments/text/A01.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "doc = nlp(text)\n",
    "sentences = list(doc.sents)\n",
    "sentence_17 = sentences[17]\n",
    "print(sentence_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WORSE', 'Worse', 'Passing', 'Worst', 'BUSIEST', 'WORST', 'where', 'BaD', 'Bad', 'BAd']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_01 = \"before\"\n",
    "ms = nlp.vocab.vectors.most_similar(\n",
    "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[word_01]]]), n = 10\n",
    ")\n",
    "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "distances = ms[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see up here are the words that are the most simiar. This could be in meaning, most frequest together-appearance, context, etc. (Not necessarily sysnonyms)\n",
    "\n",
    "We can use this to calculate document similarity using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers.  < - >  Fast food tastes very good. 0.8015960629076846\n",
      "I like salty fries and hamburgers.  < - >  Fast food tastes very good. 0.5638526601049061\n"
     ]
    }
   ],
   "source": [
    "doc_03 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc_04 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "print(doc_03, \" < - > \", doc_04, doc_03.similarity(doc_04))\n",
    "\n",
    "doc_05 = nlp(\"The Empire State Building is in New York.\")\n",
    "print(doc_03, \" < - > \", doc_04, doc_03.similarity(doc_05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LESSON 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline = a sequence of pipes or actors on data that make alterations to the data or extract information from it.\n",
    "\n",
    "\n",
    "Sample SpaCy Pipeline for NER\n",
    "\n",
    "input sentence > Entity Ruler > Entity Linker > Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f7d1967ca00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goal: add our own sentencizer to our text\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take some text from the MIT library. An example is the entire Shakespear Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94134\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\n",
    "soup = BeautifulSoup(s.content).text.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
    "nlp.max_length = 5278439\n",
    "doc = nlp(soup)\n",
    "print (len(list(doc.sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in these notes, but in the website tutorial:\n",
    "using the code above with our blank spacy \"en\" sentecizer (pipeline) model would take about 8 - 10 seconds\n",
    "while the spact \"en_core_web_sm\" model would take nearly 48 minutes.\n",
    "That's because spacy's \"en_core_web_sm\" has a bunch of other pipelines in it trying to run different things, which why the count of sentences in it is much higher (it's more accuracte).\n",
    "\n",
    "Note that for general purpose, the \"en_core_web_sm\" model is considered the most efficient one offerede by spaCy.\n",
    "\n",
    "\n",
    "Let's return to this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'sentencizer': {'assigns': ['token.is_sent_start', 'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['sents_f', 'sents_p', 'sents_r'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'sentencizer': []},\n",
       " 'attrs': {'doc.sents': {'assigns': ['sentencizer'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['sentencizer'], 'requires': []}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML', 'Deep Learning', 'AI', 'ML', 'Deep Learning', 'AI']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course=['ML','Data Science','AI','Python']\n",
    "course.insert(1,'Deep Learning')\n",
    "del course[2]\n",
    "course.remove('Python')\n",
    "course*2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90fe3afdadbf6539de53bd5bcbe637dbbaad9be665f99085db22c396248f18d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
